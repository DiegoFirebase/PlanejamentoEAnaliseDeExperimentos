---
title: "Estudo de Caso 03: Comparação de desempenho de duas configurações de um algoritmo de otimização"
author: "Diego Pontes, Elias Vieira, Matheus Bitarães"
date: "Março, 2021"
output:
    pdf_document:
    fig_caption: yes
---
```{r setup, results='hide', warning=FALSE, include = FALSE, message = FALSE, echo=FALSE}
if (!require(ggplot2, quietly = TRUE)){
      install.packages("ggplot2")
      }
if (!require(devtools, quietly = TRUE)){
      install.packages("devtools")
}
if (!require(GGally, quietly = TRUE)){
      install.packages("GGally")
      }
 if (!require(broom, quietly = TRUE)){
       devtools::install_github("dgrtwo/broom")
      }
if (!require(stats, quietly = TRUE)){
      suppressMessages(install.packages("stats"))
      }
if (!require(plotly, quietly = TRUE)){
      suppressMessages(install.packages("plotly"))
      }
if (!require(reshape2, quietly = TRUE)){
      suppressMessages(install.packages("reshape2"))
      }
if (!require(tidyr, quietly = TRUE)){
      suppressMessages(install.packages("tidyr"))
}
if (!require(pracma, quietly = TRUE)){
      suppressMessages(install.packages("pracma"))
      }
if (!require(lsr, quietly = TRUE)){
      suppressMessages(install.packages("lsr"))
      }
if (!require(car, quietly = TRUE)){
      suppressMessages(install.packages("car"))
      }
if (!require(pwr, quietly = TRUE)){
      suppressMessages(install.packages("pwr"))
      }
if (!require(multcompView, quietly = TRUE)){
      suppressMessages(install.packages("multcompView"))
      }
if (!require(multcomp, quietly = TRUE)){
      suppressMessages(install.packages("multcomp"))
      }
if (!require(lmtest, quietly = TRUE)){
      suppressMessages(install.packages("lmtest"))
      }
if (!require(effectsize, quietly = TRUE)){
      suppressMessages(install.packages("effectsize"))
      }
if (!require(CAISEr, quietly = TRUE)){
      suppressMessages(install.packages("CAISEr"))
      }
```

```{r, message = FALSE, warning = FALSE, results = 'hide', echo = FALSE}
library(stats)
library(ggplot2)
library(plotly)
library(reshape2)
library(GGally)
library(tidyr)
library(pracma)
library(lsr)
library(car)
library(pwr)
library(multcompView)
library(multcomp)
library(lmtest)
library(effectsize)
library(CAISEr)
options(Encoding="UTF-8")
```


## Descrição do problema

**Retirado do enunciado do exercício**

Suponha que um pesquisador está interessado em investigar o efeito de duas configurações distintas de um algoritmo em seu desempenho para uma dada classe de problemas de otimização.
Como forma de análise deste problema, foi proposto a tarefa de efetuar a  comparação experimental de duas configurações em uma classe de problemas, representada por um conjunto de instâncias de teste fornecida. O objetivo deste estudo é responder às seguintes perguntas:

• Há alguma diferença no desempenho médio do algoritmo quando equipado com estas diferentes configurações, para a classe de problemas de interesse? 

• Caso haja, qual a melhor configuração em termos de desempenho médio (atenção: quanto menor o valor retornado, melhor o algoritmo), e qual a magnitude das diferenças encontradas?

•Há alguma configuração que deva ser recomendada em relação à outra?


## Introdução

**Retirado do enunciado do exercício**

Algoritmos baseados em populações são uma alternativa comum para a solução de problemas de otimização em engenharia. Tais algoritmos normalmente consistem de um ciclo iterativo, no qual um conjunto de soluções-candidatas ao problema são repetidamente sujeitas a operadores de variação e seleção, de forma a promover uma exploração do espaço de variáveis do problema em busca de um ponto de ótimo (máximo ou mínimo) de uma dada função-objetivo.
Dentre estes algoritmos, um método que tem sido bastante utilizado nos últimos anos é conhecido como evolução diferencial (DE, do inglês differential evolution)(Storn and Price, 1997).

## Design do Experimento

A tarefa para este estudo de caso é a comparação experimental de duas configurações em uma classe de problemas, representada por um conjunto de instâncias de teste. As duas configurações são apresentadas a seguir:

```{r, include=TRUE}
## Configuração 1
recpars1 <- list(name = "recombination_blxAlphaBeta", alpha = 0, beta = 0)
mutpars1 <- list(name = "mutation_rand", f = 4)

## Configuração 2
recpars2 <- list(name = "recombination_linear")
mutpars2 <- list(name = "mutation_rand", f = 1.5)
```

**Retirado do enunciado do exercício**

Além disto, os seguintes parâmetros experimentais foram dados para este estudo:

• Mínima diferença de importância prática (padronizada): (d* = $\delta$*/$\sigma$) = 0.5

• Significância desejada: $\alpha$ = 0.05

• Potência mínima desejada (para o caso d = d*): $\pi$ = 1 - $\beta$ = 0.8

Para a execuçao dos experimentos, foram utilizados os pacotes ExpDE e smoof. A classe de funções de interesse para este teste é composta por funções Rosenbrock de dimensão entre 2 e 150 que podem ser geradas a partir de uma dada dimensão dim com o seguinte código:

A coleta dos resultados das execuções será de acordo com o Algoritmo 2 disponivel em campelo(2018) **CITAR CORRETAMENTE**.
**colocar o algoritmo aqui?** 

Como primeiro passo, deve-se estimar o número de instancias de acordo com o parâmetros experimentais fornecidos:

***Função que a menina usou. Autor é o Felipe Campelo...***

O método calc_instances do pacote CAISEr em linguagem R permite estimar o número de instâncias mínimas necessárias para se comparar múltiplos algoritmos, de modo que os requisitos experimentais sejam atingidos. O parâmetro número de comparações ncomparisons é dado pela seguinte equação, onde $K$ é o número de algoritmos que se deseja comparar:

\begin{equation}
  \label{eq:ncomparisons}
  \texttt{ncomparisons} = \frac{K\times(K-1)}{2}
\end{equation}

Como $K$ = 2, tem-se que ncomparisons = 1.

```{r}
# dados do trabalho
alpha <- 0.05
delta <- 0.5
beta <- 0.2

out <- calc_instances(ncomparisons = 1, 
                      d = delta, 
                      power = 1 - beta, 
                      sig.level = alpha, 
                      alternative.side = "two.sided", 
                      power.target = "mean")
cat('Número de instâncias necessárias:', out$ninstances)
```

Como pode-se concluir pelo resultado da execução do algoritmo, o número de instâncias necessárias para se realizar o experimento descrito é 34. Para que seja possível utilizar todo o intervalo de valores possíveis de D ($D \in [2, 150]$), espaçou-se uniformemente as 34 instâncias:

```{r}
num_dims <- 34
dims = round(linspace(2, 150, num_dims), digits = 0)
print(dims)
```

Seguindo o Algoritmo 2, disponivel em campelo(2018) **CITAR CORRETAMENTE**, deve-se realizar um conjunto de execuções piloto para que se possa obter os dados de média e variância das instâncias e, dessa forma, utilizar o Algoritmo 1 (disponível em campelo(2018) **CITAR CORRETAMENTE**) para executar cada instancia *n* vezes, onde *n* é o numero mínimo de instancias necessarias para comparação. O valor de *n* pode variar de acordo com cada instância, pois cada uma pode possuir diferentes variâncias.

Primeiramente será feita uma definição de funções que serão utilizadas:
```{r, include=TRUE}

# Execução de n funções de rosenbrock para determinada dimensao
executeRosenbrock <- function(dim, num_exec) {
  # Função de ronsebrock para determinada dimensao
  fn <<- function(X) {
        if(!is.matrix(X)) X <- matrix(X, nrow = 1) # <- if a single vector is passed as X
        Y <- apply(X, MARGIN = 1,
        FUN = smoof::makeRosenbrockFunction(dimensions = dim))
        return(Y)
  }
  
  # definições dadas no enunciado
  selpars <- list(name = "selection_standard")
  stopcrit <- list(names = "stop_maxeval", maxevals = 5000*dim, maxiter = 100*dim)
  probpars <- list(name = "fn", xmin = rep(-5, dim), xmax = rep(10, dim))
  popsize <- 5*dim
  
  y1 <- vector(,num_exec)
  y2 <- vector(,num_exec)
  for (i in 1:num_exec){
    
    # rodando problema para instancia 1
    out <-  ExpDE(mutpars = mutpars1,
            recpars = recpars1,
            popsize = popsize,
            selpars = selpars,
            stopcrit = stopcrit,
            probpars = probpars,
            showpars = list(show.iters = "dots", showevery = 20))
    y1[i] <- out$Fbest
    
    # rodando problema para instancia 2
    out <-  ExpDE(mutpars = mutpars2,
            recpars = recpars2,
            popsize = popsize,
            selpars = selpars,
            stopcrit = stopcrit,
            probpars = probpars,
            showpars = list(show.iters = "dots", showevery = 20))
    y2[i] <- out$Fbest
  }
  
  return(
    data.frame(
      mean1 = mean(y1),
      mean2 = mean(y2),
      sd1 = sd(y1),
      sd2 = sd(y2)))
}

# Execução de n funções de rosenbrock para uma lista de dimensões
executeRosenbrockForDims <- function(dims, num_exec){
  num_dims <- length(dims)
  mean_y1 <- vector(,num_dims)
  mean_y2 <- vector(,num_dims)
  sd_y1 <- vector(,num_dims)
  sd_y2 <- vector(,num_dims)
  
  for (d in 1:num_dims){
    dim <- dims[d]
    
    # multiplas execuções
    Y = executeRosenbrock(dim, num_exec)
    
    mean_y1[d] <- Y$mean1
    mean_y2[d] <- Y$mean2
    sd_y1[d] <- Y$sd1
    sd_y2[d] <- Y$sd2
  }
  
  data <- data.frame(
    dim = dims,
    mean.instance1 = mean_y1,
    mean.instance2 = mean_y2,
    sd.instance1 = sd_y1, 
    sd.instance2 = sd_y2)
  
  return(data)
}
```

Execução piloto com escolha inicial de 10 execuções e com os 34 blocos, obtidos anteriormente.
```{r, include=TRUE}
suppressPackageStartupMessages(library(ExpDE))
suppressPackageStartupMessages(library(smoof))

file_name = "pilot_execution_backup.csv"
num_exec <- 10

if (file.exists(file_name)) {
  
  # se ja existir uma arquivo com o dados da execução, não é necessário executar novamente. Apenas será feita a leitura do arquivo
  print("Arquivo de backup encontrado. Recuperando dados ao inves de realizar uma nova execução")
  initial_data <- read.csv(file=file_name, header = TRUE, sep=",")
  dims <- initial_data$dim
  mean_y1 <- initial_data$mean.instance1
  mean_y2 <- initial_data$mean.instance2
  sd_y1 <- initial_data$sd.instance1
  sd_y2 <- initial_data$sd.instance2
} else {
  
  # execução das funções de rosenbrock
  initial_data = executeRosenbrockForDims(dims, num_exec)
  
  # escreve no arquivo de backup os resultados coletados
  write.csv(initial_data, file = file_name)
}
initial_data$n1 <- rep(num_exec, num_dims)
initial_data$n2 <- rep(num_exec, num_dims)
```

Após esta execução, pode-se prosseguir com o Algoritmo 1. **detalhar**

O numero máximo de observações foi estipulado como 45, devido a limitações de poder computacional.

**implementar este algoritmo**
```{r}
file_name = "execution_backup.csv"
num_exec <- 10

if (file.exists(file_name)) {
  
  # se ja existir uma arquivo com o dados da execução, não é necessário executar novamente. Apenas será feita a leitura do arquivo
  print("Arquivo de backup encontrado. Recuperando dados ao inves de realizar uma nova execução")
  data <- read.csv(file=file_name, header = TRUE, sep=",")
} else {
  
  n_max <- 45
  #
}
```

a partir daqui, já teremos os dados para realizar o teste ANOVA.



falta:
-  coleta e tabulação dos dados
- testes das hipoteses
- estimacao da magnitude da diferença entre os metodos
- verificação das premissas dos testes
- conclusoes
- possiveis limitações do estudo e sugestoes de melhoria

## Atividades dos membros

**Diego**


**Elias**


**Matheus**


**Todos**


\renewcommand\refname{Referências Bibliográficas}
\bibliographystyle{unsrt}
\bibliography{referencias}

